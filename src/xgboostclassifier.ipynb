{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84152792-fb10-43cb-b1c7-98c973c86163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read in dataset\n",
    "df = pd.read_csv('C:/Users/rachr/Rowey-DATA1030-Project/wpbc.data')\n",
    "df.columns = ['ID number', 'outcome', 'time', 'radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1', 'compactness1', 'concavity1', 'concave_points1', 'symmetry1', 'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2', 'smoothness2', 'compactness2', 'concavity2', 'concave_points2', 'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3', 'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3', 'symmetry3', 'fractal_dimension3', 'tumor_size', 'lymph_node_status']\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4687bb77-a5c3-4093-9f47-055535f1a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "df['fractal_dimension_avg'] = df[['fractal_dimension1', 'fractal_dimension2', 'fractal_dimension3']].mean(axis=1)\n",
    "df['symmetry_avg'] = df[['symmetry1', 'symmetry2', 'symmetry3']].mean(axis=1)\n",
    "df['concave_points_avg'] = df[['concave_points1', 'concave_points2', 'concave_points3']].mean(axis=1)\n",
    "df['concavity_avg'] = df[['concavity1', 'concavity2', 'concavity3']].mean(axis=1)\n",
    "df['compactness_avg'] = df[['compactness1', 'compactness2', 'compactness3']].mean(axis=1)\n",
    "df['smoothness_avg'] = df[['smoothness1', 'smoothness2', 'smoothness3']].mean(axis=1)\n",
    "df['area_avg'] = df[['area1', 'area2', 'area3']].mean(axis=1)\n",
    "df['perimeter_avg'] = df[['perimeter1', 'perimeter2', 'perimeter3']].mean(axis=1)\n",
    "df['texture_avg'] = df[['texture1', 'texture2', 'texture3']].mean(axis=1)\n",
    "df['radius_avg'] = df[['radius1', 'radius2', 'radius3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b54c5e-75a2-46f3-a85d-c9ac886ccf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#dataset\n",
    "y = df['outcome']\n",
    "X = df[['time', 'radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1', 'compactness1', 'concavity1', 'concave_points1',\n",
    "        'symmetry1', 'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2', 'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
    "        'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3', 'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
    "        'symmetry3', 'fractal_dimension3', 'tumor_size', 'lymph_node_status', 'compactness_avg', 'radius_avg', 'texture_avg', 'perimeter_avg', 'area_avg',\n",
    "        'smoothness_avg', 'concavity_avg', 'concave_points_avg', 'symmetry_avg', 'fractal_dimension_avg']]\n",
    "\n",
    "#convert target variable values [N, R] to numerical data [0, 1]\n",
    "df['outcome'] = df['outcome'].replace({'N': 0, 'R': 1}).astype(int)\n",
    "\n",
    "#define categorical and numerical features\n",
    "categorical_features = ['lymph_node_status']\n",
    "numerical_features = X.columns.difference(categorical_features)\n",
    "\n",
    "#transformer to replace '?' with 'NA'\n",
    "replace_question_marks = FunctionTransformer(lambda x: x.replace('?', np.nan))\n",
    "\n",
    "#categorical pipeline\n",
    "ord_cats = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '13', '14', '15', '16', '17', '18', '20', '21', '24', '27', 'NA']\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('replace_missing', replace_question_marks),\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='NA')), #replace np.nan with 'NA'\n",
    "    ('ordinal', OrdinalEncoder(categories=[ord_cats]))\n",
    "])\n",
    "\n",
    "#preprocess all features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7d673e-c3e2-4af4-8e5e-4dda0d795ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random State: 0\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__colsample_bytree': 0.8, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 50, 'classifier__subsample': 0.8}\n",
      "  Best CV Score for this state: 0.8528\n",
      " Test Score: 0.7000\n",
      "  Test F-Score: 0.2174\n",
      "\n",
      "Random State: 42\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__colsample_bytree': 0.8, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 3, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
      "  Best CV Score for this state: 0.7899\n",
      " Test Score: 0.7750\n",
      "  Test F-Score: 0.3333\n",
      "\n",
      "Random State: 123\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'classifier__subsample': 1.0}\n",
      "  Best CV Score for this state: 0.8222\n",
      " Test Score: 0.8250\n",
      "  Test F-Score: 0.4444\n",
      "\n",
      "Random State: 2024\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 3, 'classifier__n_estimators': 100, 'classifier__subsample': 1.0}\n",
      "  Best CV Score for this state: 0.8153\n",
      " Test Score: 0.7500\n",
      "  Test F-Score: 0.1190\n",
      "\n",
      "Random State: 5678\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 200, 'classifier__subsample': 0.8}\n",
      "  Best CV Score for this state: 0.8220\n",
      " Test Score: 0.8250\n",
      "  Test F-Score: 0.5319\n",
      "\n",
      "Ultimate Best Model Across Random States:\n",
      "  Best Parameters: {'classifier__colsample_bytree': 0.8, 'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 50, 'classifier__subsample': 0.8}\n",
      "  Best CV Score: 0.8528\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#initialize pipeline with XGBClassifier\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "#parameter grid for XGBClassifier\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [10000], #set to large value and use early stopping\n",
    "    'classifier__max_depth': [1, 3, 10, 30, 100],\n",
    "    'classifier__learning_rate': [0.01],  #set to one value\n",
    "    'classifier__subsample': [0.66], #a bit less than 1 to avoid overfitting\n",
    "    'classifier__colsample_bytree': [0.9], #a bit less than 1 to avoid overfitting\n",
    "    'classifier__reg_alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__reg_lambda': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "#random states\n",
    "random_states = [0, 42, 123, 2024, 5678]\n",
    "\n",
    "#store results of each random state\n",
    "params_list = []\n",
    "cv_scores = []\n",
    "test_acc_scores = []\n",
    "test_fbeta_scores = []\n",
    "best_models = []\n",
    "\n",
    "for state in random_states:\n",
    "    print(f\"\\nRandom State: {state}\")\n",
    "    \n",
    "    #stratified train-test split\n",
    "    X_other, X_test, y_other, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=state\n",
    "    )\n",
    "    print('Test data balance:', np.unique(y_test, return_counts=True))\n",
    "    \n",
    "    #stratified K-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=state)\n",
    "    \n",
    "    #GridSearchCV for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=kf,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    #fit GridSearchCV on training data (X_other, y_other)\n",
    "    grid_search.fit(\n",
    "        X_other, y_other,\n",
    "        classifier__early_stopping_rounds=50,\n",
    "        classifier__eval_set=[(X_other, y_other)]\n",
    "    )\n",
    "    \n",
    "    #evaluate on test set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    #accuracy and f-scores\n",
    "    test_score = accuracy_score(y_test, y_test_pred)\n",
    "    fscore = fbeta_score(y_test, y_test_pred, beta=2, average='binary')\n",
    "\n",
    "    #store best parameters, scores, and models\n",
    "    params_list.append(grid_search.best_params_)\n",
    "    cv_scores.append(grid_search.best_score_)\n",
    "    test_acc_scores.append(test_score)\n",
    "    test_fbeta_scores.append(fscore)\n",
    "    best_models.append(best_model)\n",
    "\n",
    "    print(f\"  Best Parameters for this state: {grid_search.best_params_}\")\n",
    "    print(f\"  Best CV Score for this state: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"  Test Score: {test_score:.4f}\")\n",
    "    print(f\"  Test F-Score: {fscore:.4f}\")\n",
    "\n",
    "#select best model\n",
    "ultimate_best_idx = np.argmax(cv_scores)\n",
    "ultimate_best_params = params_list[ultimate_best_idx]\n",
    "ultimate_best_model = best_models[ultimate_best_idx]\n",
    "\n",
    "#print best parameters & cv score\n",
    "print(\"\\nUltimate Best Model Across Random States:\")\n",
    "print(f\"  Best Parameters: {ultimate_best_params}\")\n",
    "print(f\"  Best CV Score: {cv_scores[ultimate_best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52e74d21-e287-4673-8e45-8d4e6b6493a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Score Summary Across Random States:\n",
      "Mean Test Score: 0.7750\n",
      "Standard Deviation of Test Scores: 0.0474\n",
      "Mean F-Score: 0.3292\n",
      "Standard Deviation of F-Score: 0.1490\n"
     ]
    }
   ],
   "source": [
    "#test scores summary (accuracy and fbeta scores)\n",
    "mean_test_score = np.mean(test_scores)\n",
    "std_test_score = np.std(test_scores)\n",
    "mean_fbeta_score = np.mean(test_fbeta_scores)\n",
    "std_fbeta_score = np.std(test_fbeta_scores)\n",
    "\n",
    "print(\"\\nTest Score Summary Across Random States:\")\n",
    "print(f\"Mean Test Score: {mean_test_score:.4f}\")\n",
    "print(f\"Standard Deviation of Test Scores: {std_test_score:.4f}\")\n",
    "print(f\"Mean F-Score: {mean_fbeta_score:.4f}\")\n",
    "print(f\"Standard Deviation of F-Score: {std_fbeta_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407e98a-02e9-4cc7-a82b-6f0ffb116c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
