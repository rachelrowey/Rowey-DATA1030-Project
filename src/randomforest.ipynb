{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d33e59f-b2f1-41b3-abc2-e983ffab46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read in dataset\n",
    "df = pd.read_csv('C:/Users/rachr/Rowey-DATA1030-Project/wpbc.data')\n",
    "df.columns = ['ID number', 'outcome', 'time', 'radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1', 'compactness1', 'concavity1', 'concave_points1', 'symmetry1', 'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2', 'smoothness2', 'compactness2', 'concavity2', 'concave_points2', 'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3', 'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3', 'symmetry3', 'fractal_dimension3', 'tumor_size', 'lymph_node_status']\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdb01f9-c6e4-46cd-b49d-1afca0d4ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering\n",
    "df['fractal_dimension_avg'] = df[['fractal_dimension1', 'fractal_dimension2', 'fractal_dimension3']].mean(axis=1)\n",
    "df['symmetry_avg'] = df[['symmetry1', 'symmetry2', 'symmetry3']].mean(axis=1)\n",
    "df['concave_points_avg'] = df[['concave_points1', 'concave_points2', 'concave_points3']].mean(axis=1)\n",
    "df['concavity_avg'] = df[['concavity1', 'concavity2', 'concavity3']].mean(axis=1)\n",
    "df['compactness_avg'] = df[['compactness1', 'compactness2', 'compactness3']].mean(axis=1)\n",
    "df['smoothness_avg'] = df[['smoothness1', 'smoothness2', 'smoothness3']].mean(axis=1)\n",
    "df['area_avg'] = df[['area1', 'area2', 'area3']].mean(axis=1)\n",
    "df['perimeter_avg'] = df[['perimeter1', 'perimeter2', 'perimeter3']].mean(axis=1)\n",
    "df['texture_avg'] = df[['texture1', 'texture2', 'texture3']].mean(axis=1)\n",
    "df['radius_avg'] = df[['radius1', 'radius2', 'radius3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75779a43-0a1a-4a09-a6c1-fcd8642288e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert outcome column values [N, R] to numerical data [0, 1]\n",
    "df['outcome'] = df['outcome'].replace({'N': 0, 'R': 1}).astype(int)\n",
    "\n",
    "#print(df['outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5697bae7-9887-4c45-b6cf-dff9698ca5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing lymph_node_status\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "#missing values/encoding in lymph_node_status (ordinal)\n",
    "\n",
    "#replace '?' with 'NA'\n",
    "df['lymph_node_status'] = df['lymph_node_status'].replace('?','NA')\n",
    "\n",
    "#order categories\n",
    "ord_cats = ['0','1','2','3','4','5','6','7','8','9','10','11','13','14','15','16','17','18','20','21','24','27','NA']\n",
    "\n",
    "#OrdinalEncoder for lymph_node_status\n",
    "encoder = OrdinalEncoder(categories=[ord_cats])\n",
    "df['lymph_node_status_encoded'] = encoder.fit_transform(df[['lymph_node_status']])\n",
    "\n",
    "#print(df['lymph_node_status'])\n",
    "#print(df['lymph_node_status_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f38b08a-0d42-4818-ba70-a8e9756bd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#dataset\n",
    "y = df['outcome']\n",
    "X = df[['time', 'radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1', 'compactness1', 'concavity1', 'concave_points1',\n",
    "        'symmetry1', 'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2', 'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
    "        'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3', 'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
    "        'symmetry3', 'fractal_dimension3', 'tumor_size', 'lymph_node_status', 'compactness_avg', 'radius_avg', 'texture_avg', 'perimeter_avg', 'area_avg',\n",
    "        'smoothness_avg', 'concavity_avg', 'concave_points_avg', 'symmetry_avg', 'fractal_dimension_avg']]\n",
    "\n",
    "#convert target variable values [N, R] to numerical data [0, 1]\n",
    "df['outcome'] = df['outcome'].replace({'N': 0, 'R': 1}).astype(int)\n",
    "\n",
    "#define categorical and numerical features\n",
    "categorical_features = ['lymph_node_status']\n",
    "numerical_features = X.columns.difference(categorical_features)\n",
    "\n",
    "#transformer to replace '?' with 'NA'\n",
    "replace_question_marks = FunctionTransformer(lambda x: x.replace('?', np.nan))\n",
    "\n",
    "#categorical pipeline\n",
    "ord_cats = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '13', '14', '15', '16', '17', '18', '20', '21', '24', '27', 'NA']\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('replace_missing', replace_question_marks),\n",
    "    ('impute', SimpleImputer(strategy='constant', fill_value='NA')), #replace np.nan with 'NA'\n",
    "    ('ordinal', OrdinalEncoder(categories=[ord_cats]))\n",
    "])\n",
    "\n",
    "#preprocess all features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640f8aa8-ae60-418a-87cc-e359124aa382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random State: 0\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__max_depth': 10, 'classifier__max_features': 0.5}\n",
      "  CV Score: 0.7899\n",
      "  Test Score: 0.7500\n",
      "  Test F-Score: 0.3261\n",
      "\n",
      "Random State: 42\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__max_depth': 3, 'classifier__max_features': 0.5}\n",
      "  CV Score: 0.7964\n",
      "  Test Score: 0.7750\n",
      "  Test F-Score: 0.1220\n",
      "\n",
      "Random State: 123\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__max_depth': 10, 'classifier__max_features': 0.25}\n",
      "  CV Score: 0.7901\n",
      "  Test Score: 0.7750\n",
      "  Test F-Score: 0.1220\n",
      "\n",
      "Random State: 2024\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__max_depth': 30, 'classifier__max_features': 0.25}\n",
      "  CV Score: 0.7895\n",
      "  Test Score: 0.7750\n",
      "  Test F-Score: 0.1220\n",
      "\n",
      "Random State: 5678\n",
      "Test data balance: (array([0, 1]), array([30, 10], dtype=int64))\n",
      "  Best Parameters for this state: {'classifier__max_depth': 3, 'classifier__max_features': 0.25}\n",
      "  CV Score: 0.7899\n",
      "  Test Score: 0.7500\n",
      "  Test F-Score: 0.2273\n",
      "\n",
      "Ultimate Best Model Across Random States:\n",
      "  Best Parameters: {'classifier__max_depth': 3, 'classifier__max_features': 0.5}\n",
      "  Best CV Score: 0.7964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "#initialize pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "#define parameter grid\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [1, 3, 10, 30, 100], #log spaced\n",
    "    'classifier__max_features': [0.25, 0.5, 0.75, 1], #linearly spaced\n",
    "}\n",
    "\n",
    "#random states\n",
    "random_states = [0, 42, 123, 2024, 5678]\n",
    "\n",
    "#store results of each random state\n",
    "params_list = []\n",
    "cv_scores = []\n",
    "test_acc_scores = []\n",
    "test_fbeta_scores = []\n",
    "best_models = []\n",
    "\n",
    "for state in random_states:\n",
    "    print(f\"\\nRandom State: {state}\")\n",
    "    \n",
    "    #stratified train-test split\n",
    "    X_other, X_test, y_other, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=state\n",
    "    )\n",
    "    print('Test data balance:', np.unique(y_test, return_counts=True))\n",
    "    \n",
    "    #stratified K-Fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=state)\n",
    "    \n",
    "    #GridSearchCV for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model_pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=kf,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    #fit GridSearchCV on training data (X_other, y_other)\n",
    "    grid_search.fit(X_other, y_other)\n",
    "\n",
    "    #evaluate on test set\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    #accuracy and f-scores\n",
    "    test_score = accuracy_score(y_test, y_test_pred)\n",
    "    fscore = fbeta_score(y_test, y_test_pred, beta=2, average='binary')\n",
    "\n",
    "    #store best parameters, scores, and models\n",
    "    params_list.append(grid_search.best_params_)\n",
    "    cv_scores.append(grid_search.best_score_)\n",
    "    test_acc_scores.append(test_score)\n",
    "    test_fbeta_scores.append(fscore)\n",
    "    best_models.append(best_model)\n",
    "\n",
    "    print(f\"  Best Parameters for this state: {grid_search.best_params_}\")\n",
    "    print(f\"  CV Score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"  Test Score: {test_score:.4f}\")\n",
    "    print(f\"  Test F-Score: {fscore:.4f}\")\n",
    "\n",
    "#select best model\n",
    "ultimate_best_idx = np.argmax(cv_scores)\n",
    "ultimate_best_params = params_list[ultimate_best_idx]\n",
    "ultimate_best_model = best_models[ultimate_best_idx]\n",
    "\n",
    "#print best parameters & cv score\n",
    "print(\"\\nUltimate Best Model Across Random States:\")\n",
    "print(f\"  Best Parameters: {ultimate_best_params}\")\n",
    "print(f\"  Best CV Score: {cv_scores[ultimate_best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d71bea20-1026-48b9-b90f-449550c26638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Score Summary Across Random States:\n",
      "Mean Test Score: 0.7650\n",
      "Standard Deviation of Test Scores: 0.0122\n",
      "Mean F-Score: 0.1838\n",
      "Standard Deviation of F-Score: 0.0820\n"
     ]
    }
   ],
   "source": [
    "#test scores summary (accuracy and fbeta scores)\n",
    "mean_test_acc_score = np.mean(test_acc_scores)\n",
    "std_test_score = np.std(test_acc_scores)\n",
    "mean_fbeta_score = np.mean(test_fbeta_scores)\n",
    "std_fbeta_score = np.std(test_fbeta_scores)\n",
    "\n",
    "print(\"\\nTest Score Summary Across Random States:\")\n",
    "print(f\"Mean Test Score: {mean_test_acc_score:.4f}\")\n",
    "print(f\"Standard Deviation of Test Scores: {std_test_score:.4f}\")\n",
    "print(f\"Mean F-Score: {mean_fbeta_score:.4f}\")\n",
    "print(f\"Standard Deviation of F-Score: {std_fbeta_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab081b6a-ce2f-4831-9806-ed9e977684eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
